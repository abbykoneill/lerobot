{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e68963bd",
   "metadata": {},
   "source": [
    "# Safety with GenAI in Robotics\n",
    "\n",
    "### Lab Table of Contents\n",
    "* Part 1\n",
    "    1. [1_imitation_learning.ipynb](https://github.com/abbykoneill/lerobot/blob/main/lab_part_1/1_imitation_learning.ipynb)\n",
    "* **Part 2**\n",
    "    1. [1_chatgpt.ipynb](https://github.com/abbykoneill/lerobot/blob/main/lab_part2/1_chatgpt.ipynb)\n",
    "    2. [2_CLIP.ipynb](https://github.com/abbykoneill/lerobot/blob/main/lab_part2/2_CLIP.ipynb)\n",
    "    3. [3_VLM_BLIP.ipynb](https://github.com/abbykoneill/lerobot/blob/main/lab_part2/3_VLM_BLIP.ipynb)\n",
    "    4. [4_VLA.ipynb](https://github.com/abbykoneill/lerobot/blob/main/lab_part2/4_VLA.ipynb)\n",
    "    5. **[5_safety.ipynb](https://github.com/abbykoneill/lerobot/blob/main/lab_part2/5_safety.ipynb)**\n",
    "* [Lab Checkoff](https://github.com/abbykoneill/lerobot/blob/main/lab_part2/checkoff.txt)\n",
    "\n",
    "## Exploring Safety Concerns with Generative AI in Robotic Systems\n",
    "As you have walked through the 4 preivous notebooks in this section of the lab, you have experimented with several different generative AI models that are currently being used in robotic systems for research, education, and more. \n",
    "\n",
    "While, these models are powerful tools with the ability to match images, text, and action tokens in order to control or plan control for complex systems, relying too heavily on their autonomy poses safety concerns for the system and users in the environment.\n",
    "\n",
    "This notebook will guide you through critically thinking about potential safety concerns with introducing generative AI into robotic systems that depend on highly trustworthy actions.\n",
    "\n",
    "Walk through the following cells and prompts. Discuss answers to the questions with your lab partner. \n",
    "\n",
    ">When you have finished this notebook, ask a TA to complete the lab checkoff."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84585c48",
   "metadata": {},
   "source": [
    "## What is Generative AI?\n",
    "\n",
    "1. Using what you have learned and explored through this lab, create a concrete 2-3 sentence definition of generative AI. Give one example of a GenAI model, not used in this lab, and outline the inputs, outputs, and uses cases for this model. You can either use knowledge of models you have used in your day-to-day, or search online for new models that are similar to what we have explored in this lab.\n",
    "\n",
    "2. Compare and contrast the model you chose above to 2 of the 4 models in this lab (ChatGPT, CLIP, BLIP, SmolVLA)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d15437",
   "metadata": {},
   "source": [
    "## Safety Concerns\n",
    "\n",
    "For the following two questions, think about some considerations with GenAI models.\n",
    "* Could the GenAI model provide incorrect or misleading information?\n",
    "* Could the GenAI model produce harmful or inappropriate content?\n",
    "* How might AI affect privacy, security, misinformation, etc?\n",
    "* Could GenAI models replace any types of work currently done with humans?\n",
    "\n",
    "### Questions\n",
    "\n",
    "3. List three tasks that might be given to an autonomous robot system, output from a GenAI model, that could be misinterpreted or performed incorrectly by the system (either due to ambiguity, physical limitations, etc).\n",
    "\n",
    "4. For each of the three output tasks you chose above, list an ethical concern that might arise from blindly trusting the robot with the GenAI action token without human intervention.\n",
    "\n",
    "5. For each of the three outputs, explain why the associated safety and ethical concerns are important in terms of real-world physical application. How could this influence the future behaviors of the system?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e712d4c",
   "metadata": {},
   "source": [
    "## Addressing Safety Concerns\n",
    "\n",
    "Potential safety concerns do not completely discredit GenAI models- we just need to know how to mitigate model limitations before they cascade into safety/ethical concerns.\n",
    "\n",
    "6. For each of the three (output, safety concern, ethical concern) pairs you outlined above, suggest two possible modifications to the model output (action token) and two possible modifications to the physical system that could prevent the safety and ethical concerns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ab328c",
   "metadata": {},
   "source": [
    "## One Safety Concern Example: Bounding Boxes\n",
    "\n",
    "Consider a system with a 4-joint physical manipulator arm as shown below.\n",
    "\n",
    "![Robotic Arm Manipulator](robot_task_images/robot-arm.png)\n",
    "\n",
    "7. How many degrees of freedom does this robot have?\n",
    "\n",
    "One potential safety concern with blindly relying on GenAI output action tokens for this system is the physical limitation and reach of the manipulator arm. For example, it can be difficult for the model to grasp physical dimensions of the scene, environment, and physical robot solely from input images, causing it to lack that physical constraint unless explicitly provided by the user as accompanying input text.\n",
    "\n",
    "Inputing physically unreachable coordinates to the manipulator is a concern because it can be unpredictable what the system will do when it realizes it cannot reach the goal, if it realizes that. There is also a chance it does not realize and continues to try to reach the impossible target through other unsafe means.\n",
    "\n",
    "One method for mitigating this safety concern is to implement a 3D bounding box that represents the physically reachable envelope of the robot arm.\n",
    "\n",
    "8. Why does a 3D bounding box help prevent the unsafe situation presented above?\n",
    "\n",
    "9. Create pseudocode for implementing a 3D bounding box around a robot manipulator arm. Choose your own physical dimensions of the arm for your code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5eb427",
   "metadata": {},
   "source": [
    "## Safety Mitigation in the Real-World\n",
    "\n",
    "10. Find a recent research article (within the last couple of years) that discusses new strategies for implementing some GenAI model into some physical robotic system. Record the paper title, where it is published, and who are the contributors/authors.\n",
    "\n",
    "11. List three potential safety concerns with the set up in the paper. Do the authors address safety concerns in the paper?\n",
    "\n",
    "12. List a way that their model implementation could be extended to mitigate or prevent one of the identified safety concerns (either one that you identified above or one identified by the authors in the paper)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff6086f",
   "metadata": {},
   "source": [
    ">**Congratulations! You have finished section 2 of the lab.** Find a lab TA to complete the final checkoff."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba903ad0",
   "metadata": {},
   "source": [
    "### Continue to\n",
    "[Lab Checkoff](https://github.com/abbykoneill/lerobot/blob/main/lab_part2/checkoff.txt)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
